{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from time import process_time\n",
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load zones 20, 19, and 18\n",
    "t0_start = process_time() \n",
    "\n",
    "AIS_raw_20 = pd.read_csv('AIS_2017_12_Zone20.csv', header=0)\n",
    "AIS_raw_19 = pd.read_csv('AIS_2017_12_Zone19.csv', header=0)\n",
    "AIS_raw_18 = pd.read_csv('AIS_2017_12_Zone18.csv', header=0)\n",
    "\n",
    "t0_end = process_time()\n",
    "load_time = t0_end-t0_start\n",
    "loaded_rows = len(AIS_raw_20)+len(AIS_raw_19)+len(AIS_raw_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataframes into a single dataframe\n",
    "t1_start = process_time() \n",
    "\n",
    "zones_comb = pd.concat([AIS_raw_20, AIS_raw_19, AIS_raw_18]).reset_index(drop=True)\n",
    "\n",
    "t1_end = process_time()\n",
    "combine_time = t1_end-t1_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data frame of the NaN values of status, length, width, and vessel type and only keep non-useful status values.\n",
    "t2_start = process_time() \n",
    "\n",
    "zones_clean = zones_comb[['MMSI','BaseDateTime','LAT','LON','VesselType','Status','Length','Width']].dropna()\n",
    "zones_clean = zones_clean[zones_clean['Status'].isin({'at anchor', 'moored', 'power-driven vessel pushing ahead or towing alongside', \\\n",
    "                                                    'power-driven vessel towing astern','under way using engine'})].reset_index(drop=True)\n",
    "t2_end = process_time()\n",
    "clean_time = t2_end-t2_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning by dropping the ships that do not have a change in status\n",
    "t3_start = process_time() \n",
    "\n",
    "zones_clean_grouped = zones_clean.groupby(\"MMSI\")['Status'].apply(set).reset_index()\n",
    "\n",
    "for index,row in zones_clean_grouped.iterrows():\n",
    "    if len(row['Status']) < 2:\n",
    "        zones_clean_grouped.drop(index, inplace=True) \n",
    "     \n",
    "useful_ships = zones_clean_grouped['MMSI'].unique().tolist()\n",
    "zones_useful = zones_clean[zones_clean['MMSI'].isin(useful_ships)]\n",
    "\n",
    "t3_end = process_time()\n",
    "clean_time2 = t3_end-t3_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group the data by MMSI (ships) then filter out values of lat and lon where this is not a change in status.\n",
    "t4_start = process_time() \n",
    "\n",
    "zones_ordered = zones_useful.sort_values(['MMSI','BaseDateTime'],ascending=True)\n",
    "zones_comb_list = zones_ordered.groupby(\"MMSI\").agg({'Status':list, 'LAT':list, 'LON':list, 'BaseDateTime':list, \\\n",
    "                                                    'VesselType':set, 'Length':set, 'Width':set}).reset_index()\n",
    "\n",
    "def compress_stat(row):\n",
    "    stat = row['Status']\n",
    "    time = row['BaseDateTime']\n",
    "    lon = row['LON']\n",
    "    lat = row['LAT']\n",
    "    vals = [(stat[i+1],time[i+1],lon[i+1],lat[i+1]) for i,j,k in zip(np.arange(len(stat)-1), stat[:-1], stat[1:]) if (j!=k or i==0 )]\n",
    "    return [(j[1],j[2],j[3]) for i,j in enumerate(vals) if j[0] in {'moored','at anchor'}]\n",
    "\n",
    "zones_comb_list['Status_comp'] = zones_comb_list.apply(lambda row: compress_stat(row), axis=1)\n",
    "zones_compressed = zones_comb_list.drop(['Status','LAT','LON','BaseDateTime'], axis=1)\n",
    "\n",
    "for index,rows in zones_compressed.iterrows():  \n",
    "    if len(rows['Status_comp']) < 2:\n",
    "        zones_compressed.drop(index, inplace=True)\n",
    "\n",
    "t4_end = process_time()\n",
    "group_time = t4_end - t4_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dataframe now with the data only including when a ship enters port\n",
    "t5_start = process_time() \n",
    "\n",
    "zones_expanded = zones_compressed.explode('Status_comp').reset_index(drop=True)\n",
    "zones_expanded['Date-Time'] = [i[0] for i in zones_expanded['Status_comp'].to_list()]\n",
    "zones_expanded['LON'] = [i[1] for i in zones_expanded['Status_comp'].to_list()]\n",
    "zones_expanded['LAT'] = [i[2] for i in zones_expanded['Status_comp'].to_list()]\n",
    "zones_expanded['Length'] = zones_expanded['Length'].apply(lambda row: list(row)[0])\n",
    "zones_expanded['Width'] = zones_expanded['Width'].apply(lambda row: list(row)[0])\n",
    "zones_expanded['VesselType'] = zones_expanded['VesselType'].apply(lambda row: list(row)[0])\n",
    "zones_expanded = zones_expanded.drop('Status_comp', axis=1)\n",
    "\n",
    "#Placeholder Carbon calculator\n",
    "def carbonCalc(length,width,vessel):\n",
    "    return length*width*vessel\n",
    "\n",
    "zones_expanded['C02_output'] = zones_expanded.apply(lambda row: carbonCalc(row['Length'],row['Width'],row['VesselType']), axis=1)\n",
    "\n",
    "t5_end = process_time() \n",
    "expand_time = t5_end - t5_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Ports based on proximity of ships anchoring/mooring near eachother\n",
    "#Create a port_reference that maps a port to a Lat,Lon\n",
    "\n",
    "lon = zones_expanded['LON'].to_list()\n",
    "lat = zones_expanded['LAT'].to_list()\n",
    "Coords = np.array([[i,j] for i,j in zip(lon,lat)])\n",
    "clustering = DBSCAN(eps=0.1, min_samples=2).fit(Coords)\n",
    "\n",
    "zones_expanded['Port_ID'] = clustering.labels_\n",
    "port_reference = zones_expanded.groupby('Port_ID').mean()[['LON','LAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create graph that incluses start port and end port\n",
    "zones_grouped = zones_expanded.groupby('MMSI').agg({'Port_ID':list}).reset_index()\n",
    "len_list = zones_grouped['Port_ID'].apply(lambda x: len(x)).to_list()\n",
    "len_list = np.cumsum(len_list)\n",
    "len_list = [i-1 for i in len_list][:-1]\n",
    "zones_graph = pd.DataFrame()\n",
    "zones_graph['Start_Port'] = zones_expanded['Port_ID'][:-1].to_list()\n",
    "zones_graph['End_Port'] = zones_expanded['Port_ID'][1:].to_list()\n",
    "zones_graph['MMSI'] = zones_expanded['MMSI'][:-1].to_list()\n",
    "zones_graph['Date-Time'] = zones_expanded['Date-Time'][:-1].to_list()\n",
    "zones_graph['VesselType'] = zones_expanded['VesselType'][:-1].to_list()\n",
    "zones_graph['ShipLength'] = zones_expanded['Length'][:-1].to_list()\n",
    "zones_graph['ShipWidth'] = zones_expanded['Width'][:-1].to_list()\n",
    "zones_graph['C02_output'] = zones_expanded['C02_output'][:-1].to_list()\n",
    "\n",
    "#Kilometers (as the crow flies)\n",
    "def distCalc(start,end):\n",
    "    start_lat = math.radians(port_reference['LAT'][start])    \n",
    "    end_lat = math.radians(port_reference['LAT'][end])    \n",
    "    start_lon = math.radians(port_reference['LON'][start])    \n",
    "    end_lon = math.radians(port_reference['LON'][end])    \n",
    "    dlon = end_lon - start_lon\n",
    "    dlat = end_lat - start_lat\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(start_lat) * math.cos(end_lat) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return 6373.0 * c #6373.0 is the radius of the earth in km\n",
    "\n",
    "zones_graph = zones_graph.drop(len_list)\n",
    "zones_graph['DistBetweenPorts'] = zones_graph.apply(lambda row: distCalc(row['Start_Port'],row['End_Port']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zones_expanded.to_csv('Zones_expanded.csv', index=False)\n",
    "port_reference.to_csv('Port_reference.csv')\n",
    "zones_graph.to_csv('Zones_graphed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Time: 157.609375\n",
      "Combine Time: 128.921875\n",
      "Clean Time: 47.46875\n",
      "Clean Time 2: 19.03125\n",
      "Group Time: 56.265625\n",
      "Expand Time: 0.390625\n",
      "Total Time: 409.6875\n"
     ]
    }
   ],
   "source": [
    "print('Load Time:',load_time)\n",
    "print('Combine Time:',combine_time)\n",
    "print('Clean Time:',clean_time)\n",
    "print('Clean Time 2:',clean_time2)\n",
    "print('Group Time:',group_time)\n",
    "print('Expand Time:',expand_time)\n",
    "print('Total Time:',load_time+combine_time+clean_time+clean_time2+group_time+expand_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
